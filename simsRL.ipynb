{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "WARNING:tensorflow:From c:\\Users\\Neo\\anaconda3\\envs\\ACML\\Lib\\site-packages\\ray\\rllib\\utils\\framework.py:130: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pygame\n",
    "from collections import deque\n",
    "from scipy.spatial import cKDTree\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from gym import spaces\n",
    "\n",
    "class SugarscapeEnv(MultiAgentEnv):\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initialize the Sugarscape environment.\n",
    "        \n",
    "        Args:\n",
    "            config (dict): Configuration parameters for the environment.\n",
    "        \"\"\"\n",
    "        # Extract configuration parameters\n",
    "        self.width = config.get(\"width\", 50)\n",
    "        self.height = config.get(\"height\", 50)\n",
    "        self.num_agents = config.get(\"num_agents\", 100)\n",
    "        self.cell_size = config.get(\"cell_size\", 10)\n",
    "        self.show_sugar_levels = config.get(\"show_sugar_levels\", False)\n",
    "        self.show_broadcast_radius = config.get(\"show_broadcast_radius\", False)\n",
    "        self.show_agent_paths = config.get(\"show_agent_paths\", False)\n",
    "        self.broadcast_radius_default = config.get(\"broadcast_radius\", 5)\n",
    "        self.seed = config.get(\"seed\", None)\n",
    "        self.render_mode = config.get(\"render_mode\", False)  # Enable rendering if True\n",
    "\n",
    "        # Initialize random number generators with the seed for reproducibility\n",
    "        if self.seed is not None:\n",
    "            random.seed(self.seed)\n",
    "            np.random.seed(self.seed)\n",
    "\n",
    "        # Environment parameters\n",
    "        self.params = {\n",
    "            'max_sugar': 5,\n",
    "            'growth_rate': 1,\n",
    "            'sugar_peak_frequency': 0.04,\n",
    "            'sugar_peak_spread': 6,\n",
    "            'job_center_duration': (40, 100),\n",
    "            'vision_range': 1,\n",
    "            'message_expiry': 15,\n",
    "            'max_relay_messages': 10\n",
    "        }\n",
    "\n",
    "        # Initialize job centers and sugar landscape\n",
    "        self.job_centers = []\n",
    "        self.sugar = np.zeros((self.height, self.width), dtype=int)\n",
    "        self.create_initial_sugar_peaks()\n",
    "        self.update_sugar_landscape()\n",
    "        self.max_sugar_landscape = self.sugar.copy()\n",
    "\n",
    "        # Initialize agents\n",
    "        self.agents = self.initialize_agents()\n",
    "        self.agent_positions = set((agent['x'], agent['y']) for agent in self.agents)\n",
    "        self.dead_agents = []\n",
    "\n",
    "        # Initialize Pygame if rendering is enabled\n",
    "        if self.render_mode:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.width * self.cell_size, self.height * self.cell_size))\n",
    "            pygame.display.set_caption(\"Sugarscape Simulation - With Broadcasting\")\n",
    "            self.clock = pygame.time.Clock()\n",
    "            self.font = pygame.font.Font(None, 10)\n",
    "\n",
    "        # Data tracking\n",
    "        self.population_history = []\n",
    "        self.average_wealth_history = []\n",
    "        self.gini_coefficient_history = []\n",
    "        self.timestep = 0\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        # Actions: 0: stay, 1: up, 2: up-right, 3: right, 4: down-right,\n",
    "        #          5: down, 6: down-left, 7: left, 8: up-left\n",
    "        self.action_space = spaces.Discrete(9)\n",
    "\n",
    "        # Observation: visible sugar grid + agent's own sugar and metabolism\n",
    "        # For vision_range=1, visible grid is 3x3\n",
    "        # Flattened to a vector and concatenated with agent's sugar and metabolism\n",
    "        self.observation_space = spaces.Box(low=0, high=self.params['max_sugar'],\n",
    "                                            shape=(3 * 3 + 2,), dtype=np.float32)\n",
    "\n",
    "    def create_initial_sugar_peaks(self, num_peaks=2):\n",
    "        \"\"\"\n",
    "        Create initial sugar peaks (job centers).\n",
    "        \n",
    "        Args:\n",
    "            num_peaks (int): Number of initial sugar peaks.\n",
    "        \"\"\"\n",
    "        for _ in range(num_peaks):\n",
    "            self.create_job_center()\n",
    "        self.update_sugar_landscape()\n",
    "\n",
    "    def create_job_center(self):\n",
    "        \"\"\"\n",
    "        Create a single job center with random location and duration.\n",
    "        \"\"\"\n",
    "        x, y = np.random.randint(0, self.width), np.random.randint(0, self.height)\n",
    "        duration = np.random.randint(*self.params['job_center_duration'])\n",
    "        self.job_centers.append({\n",
    "            'x': x, 'y': y,\n",
    "            'duration': duration,\n",
    "            'max_sugar': self.params['max_sugar']\n",
    "        })\n",
    "\n",
    "    def update_sugar_landscape(self):\n",
    "        \"\"\"\n",
    "        Update the sugar landscape based on active job centers.\n",
    "        \"\"\"\n",
    "        self.sugar = np.zeros((self.height, self.width))\n",
    "        for center in self.job_centers:\n",
    "            x_grid, y_grid = np.meshgrid(np.arange(self.width), np.arange(self.height))\n",
    "            distance = np.sqrt((x_grid - center['x']) ** 2 + (y_grid - center['y']) ** 2)\n",
    "            sugar_level = center['max_sugar'] * np.exp(-distance ** 2 / (2 * self.params['sugar_peak_spread'] ** 2))\n",
    "            self.sugar += sugar_level\n",
    "        self.sugar = np.clip(self.sugar, 0, self.params['max_sugar'])\n",
    "        self.sugar = np.round(self.sugar).astype(int)\n",
    "\n",
    "    def initialize_agents(self):\n",
    "        \"\"\"\n",
    "        Initialize agents with unique positions.\n",
    "        \n",
    "        Returns:\n",
    "            list: List of agent dictionaries.\n",
    "        \"\"\"\n",
    "        agents = []\n",
    "        available_positions = set((x, y) for x in range(self.width) for y in range(self.height))\n",
    "        for i in range(self.num_agents):\n",
    "            if not available_positions:\n",
    "                break\n",
    "            x, y = available_positions.pop()\n",
    "            agents.append(self.create_agent(i, x, y))\n",
    "        return agents\n",
    "\n",
    "    def create_agent(self, id, x, y):\n",
    "        \"\"\"\n",
    "        Create a single agent with random sugar and metabolism.\n",
    "        \n",
    "        Args:\n",
    "            id (int): Unique identifier for the agent.\n",
    "            x (int): X-coordinate of the agent.\n",
    "            y (int): Y-coordinate of the agent.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Agent dictionary with attributes.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'id': id,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'sugar': np.random.randint(40, 80),\n",
    "            'metabolism': np.random.randint(1, 3),\n",
    "            'vision': self.params['vision_range'],\n",
    "            'broadcast_radius': max(1, int(np.random.normal(self.broadcast_radius_default,\n",
    "                                                              self.broadcast_radius_default / 3))),\n",
    "            'messages': deque(maxlen=100),\n",
    "            'destination': None\n",
    "        }\n",
    "\n",
    "    def get_visible_sugar(self, agent):\n",
    "        \"\"\"\n",
    "        Get the visible sugar grid for an agent based on its vision range.\n",
    "        \n",
    "        Args:\n",
    "            agent (dict): Agent dictionary.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Visible sugar grid.\n",
    "        \"\"\"\n",
    "        x, y = agent['x'], agent['y']\n",
    "        vision = agent['vision']\n",
    "        x_min = max(0, x - vision)\n",
    "        x_max = min(self.width, x + vision + 1)\n",
    "        y_min = max(0, y - vision)\n",
    "        y_max = min(self.height, y + vision + 1)\n",
    "        visible_area = self.sugar[y_min:y_max, x_min:x_max]\n",
    "        # Normalize sugar levels\n",
    "        visible_area = visible_area / self.params['max_sugar']\n",
    "        # If vision_range=1, pad the visible_area to 3x3\n",
    "        if vision == 1:\n",
    "            pad_y = 3 - visible_area.shape[0]\n",
    "            pad_x = 3 - visible_area.shape[1]\n",
    "            visible_area = np.pad(visible_area, ((0, pad_y), (0, pad_x)), 'constant')\n",
    "        return visible_area.flatten()\n",
    "\n",
    "    def broadcast_messages(self):\n",
    "        \"\"\"\n",
    "        Broadcast messages from all agents to their neighbors within broadcast radius.\n",
    "        \"\"\"\n",
    "        if not self.agents:\n",
    "            return  # No agents to broadcast\n",
    "\n",
    "        # Extract agent positions\n",
    "        positions = np.array([[agent['x'], agent['y']] for agent in self.agents])\n",
    "\n",
    "        # Build cKDTree for efficient spatial queries\n",
    "        tree = cKDTree(positions)\n",
    "\n",
    "        # Query all neighbors within broadcast_radius for each agent\n",
    "        all_neighbors = tree.query_ball_point(positions, self.broadcast_radius_default)\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            # Create the message from this agent\n",
    "            visible_sugar = self.get_visible_sugar(agent).sum()\n",
    "            message = {\n",
    "                'sender_id': agent['id'],\n",
    "                'sugar_amount': visible_sugar,\n",
    "                'timestep': self.timestep,\n",
    "                'x': agent['x'],\n",
    "                'y': agent['y']\n",
    "            }\n",
    "\n",
    "            neighbors = all_neighbors[i]\n",
    "            for neighbor_idx in neighbors:\n",
    "                if neighbor_idx != i:\n",
    "                    self.agents[neighbor_idx]['messages'].append(message)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the environment to an initial state.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Dictionary of observations for each agent.\n",
    "        \"\"\"\n",
    "        # Reset job centers and sugar landscape\n",
    "        self.job_centers = []\n",
    "        self.create_initial_sugar_peaks()\n",
    "        self.update_sugar_landscape()\n",
    "\n",
    "        # Reset agents\n",
    "        self.agents = self.initialize_agents()\n",
    "        self.agent_positions = set((agent['x'], agent['y']) for agent in self.agents)\n",
    "        self.dead_agents = []\n",
    "        self.timestep = 0\n",
    "\n",
    "        # Reset messages\n",
    "        for agent in self.agents:\n",
    "            agent['messages'].clear()\n",
    "\n",
    "        # If rendering is enabled, reset Pygame display\n",
    "        if self.render_mode:\n",
    "            self.screen.fill((255, 255, 255))\n",
    "            pygame.display.flip()\n",
    "\n",
    "        # Return initial observations\n",
    "        observations = {agent['id']: self.get_observation(agent) for agent in self.agents}\n",
    "        return observations\n",
    "\n",
    "    def get_observation(self, agent):\n",
    "        \"\"\"\n",
    "        Get the observation for a single agent.\n",
    "        \n",
    "        Args:\n",
    "            agent (dict): Agent dictionary.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Observation vector.\n",
    "        \"\"\"\n",
    "        visible_sugar = self.get_visible_sugar(agent)\n",
    "        # Normalize agent's own sugar and metabolism\n",
    "        sugar_norm = agent['sugar'] / 100  # Assuming max sugar is 100\n",
    "        metabolism_norm = agent['metabolism'] / 10  # Assuming max metabolism is 10\n",
    "        observation = np.concatenate([visible_sugar, [sugar_norm, metabolism_norm]])\n",
    "        return observation.astype(np.float32)\n",
    "\n",
    "    def step(self, action_dict):\n",
    "        \"\"\"\n",
    "        Execute one time step within the environment.\n",
    "        \n",
    "        Args:\n",
    "            action_dict (dict): Actions for each agent.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: observations, rewards, dones, infos\n",
    "        \"\"\"\n",
    "        # Apply actions to agents\n",
    "        for agent in self.agents:\n",
    "            agent_id = agent['id']\n",
    "            if agent_id in action_dict:\n",
    "                action = action_dict[agent_id]\n",
    "                # Map action to movement\n",
    "                dx, dy = self.action_to_direction(action)\n",
    "                new_x = agent['x'] + dx\n",
    "                new_y = agent['y'] + dy\n",
    "\n",
    "                # Check if the new position is within bounds and not occupied\n",
    "                if (0 <= new_x < self.width and 0 <= new_y < self.height and\n",
    "                        (new_x, new_y) not in self.agent_positions):\n",
    "                    # Update agent position\n",
    "                    self.agent_positions.remove((agent['x'], agent['y']))\n",
    "                    agent['x'] = new_x\n",
    "                    agent['y'] = new_y\n",
    "                    self.agent_positions.add((new_x, new_y))\n",
    "\n",
    "                    # Update destination if agent was moving towards it\n",
    "                    if agent['destination'] and (new_x, new_y) == agent['destination']:\n",
    "                        agent['destination'] = None\n",
    "\n",
    "        # Collect sugar and apply metabolism\n",
    "        for agent in self.agents:\n",
    "            collected_sugar = self.sugar[agent['y'], agent['x']]\n",
    "            agent['sugar'] += collected_sugar\n",
    "            self.sugar[agent['y'], agent['x']] = 0\n",
    "            agent['sugar'] -= agent['metabolism']\n",
    "            agent['sugar'] = int(agent['sugar'])  # Ensure agent sugar is an integer\n",
    "\n",
    "        # Broadcast messages\n",
    "        self.broadcast_messages()\n",
    "\n",
    "        # Clean up expired messages\n",
    "        for agent in self.agents:\n",
    "            agent['messages'] = deque(\n",
    "                [msg for msg in agent['messages'] if self.timestep - msg['timestep'] <= self.params['message_expiry']],\n",
    "                maxlen=100)\n",
    "\n",
    "        # Handle agent death\n",
    "        alive_agents = []\n",
    "        for agent in self.agents:\n",
    "            if agent['sugar'] <= 0:\n",
    "                self.dead_agents.append({'x': agent['x'], 'y': agent['y'], 'death_time': self.timestep})\n",
    "                self.agent_positions.remove((agent['x'], agent['y']))\n",
    "            else:\n",
    "                alive_agents.append(agent)\n",
    "        self.agents = alive_agents\n",
    "\n",
    "        self.dead_agents = [agent for agent in self.dead_agents if self.timestep - agent['death_time'] <= 5]\n",
    "\n",
    "        # Update job centers\n",
    "        for center in self.job_centers:\n",
    "            center['duration'] -= 1\n",
    "        self.job_centers = [center for center in self.job_centers if center['duration'] > 0]\n",
    "        if np.random.random() < self.params['sugar_peak_frequency']:\n",
    "            self.create_job_center()\n",
    "        self.update_sugar_landscape()\n",
    "\n",
    "        # Collect data\n",
    "        self.collect_data()\n",
    "\n",
    "        # Increment timestep\n",
    "        self.timestep += 1\n",
    "\n",
    "        # Prepare observations, rewards, dones, infos\n",
    "        observations = {agent['id']: self.get_observation(agent) for agent in self.agents}\n",
    "        rewards = {agent['id']: agent['sugar'] for agent in self.agents}  # Reward based on sugar\n",
    "        dones = {agent['id']: False for agent in self.agents}\n",
    "        dones['__all__'] = False  # Simulation runs until max_timesteps\n",
    "\n",
    "        # Optionally render the environment\n",
    "        if self.render_mode:\n",
    "            self.render()\n",
    "\n",
    "        return observations, rewards, dones, {}\n",
    "\n",
    "    def action_to_direction(self, action):\n",
    "        \"\"\"\n",
    "        Convert discrete action to movement direction.\n",
    "        \n",
    "        Args:\n",
    "            action (int): Action integer.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (dx, dy)\n",
    "        \"\"\"\n",
    "        # Actions: 0: stay, 1: up, 2: up-right, 3: right, 4: down-right,\n",
    "        #          5: down, 6: down-left, 7: left, 8: up-left\n",
    "        action_map = {\n",
    "            0: (0, 0),\n",
    "            1: (0, -1),\n",
    "            2: (1, -1),\n",
    "            3: (1, 0),\n",
    "            4: (1, 1),\n",
    "            5: (0, 1),\n",
    "            6: (-1, 1),\n",
    "            7: (-1, 0),\n",
    "            8: (-1, -1)\n",
    "        }\n",
    "        return action_map.get(action, (0, 0))  # Default to stay if invalid action\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Render the environment using Pygame.\n",
    "        \"\"\"\n",
    "        self.screen.fill((255, 255, 255))\n",
    "\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                sugar_level = self.sugar[y, x]\n",
    "                color = self.get_color(sugar_level)\n",
    "                pygame.draw.rect(self.screen, color,\n",
    "                                 (x * self.cell_size, y * self.cell_size, self.cell_size, self.cell_size))\n",
    "\n",
    "                if self.show_sugar_levels:\n",
    "                    sugar_text = self.font.render(f\"{sugar_level}\", True, (0, 0, 0))\n",
    "                    text_rect = sugar_text.get_rect(center=(x * self.cell_size + self.cell_size // 2,\n",
    "                                                            y * self.cell_size + self.cell_size // 2))\n",
    "                    self.screen.blit(sugar_text, text_rect)\n",
    "\n",
    "        for dead_agent in self.dead_agents:\n",
    "            pygame.draw.circle(self.screen, (128, 128, 128),\n",
    "                               (int(dead_agent['x'] * self.cell_size + self.cell_size / 2),\n",
    "                                int(dead_agent['y'] * self.cell_size + self.cell_size / 2)),\n",
    "                               int(self.cell_size / 3))\n",
    "\n",
    "        for agent in self.agents:\n",
    "            if self.show_broadcast_radius:\n",
    "                pygame.draw.circle(self.screen, (200, 200, 200),\n",
    "                                   (int(agent['x'] * self.cell_size + self.cell_size / 2),\n",
    "                                    int(agent['y'] * self.cell_size + self.cell_size / 2)),\n",
    "                                   int(agent['broadcast_radius'] * self.cell_size), 1)\n",
    "\n",
    "            pygame.draw.circle(self.screen, (255, 0, 0),\n",
    "                               (int(agent['x'] * self.cell_size + self.cell_size / 2),\n",
    "                                int(agent['y'] * self.cell_size + self.cell_size / 2)),\n",
    "                               int(self.cell_size / 3))\n",
    "\n",
    "            if self.show_agent_paths and agent['destination']:\n",
    "                pygame.draw.line(self.screen, (0, 255, 0),\n",
    "                                 (int(agent['x'] * self.cell_size + self.cell_size / 2),\n",
    "                                  int(agent['y'] * self.cell_size + self.cell_size / 2)),\n",
    "                                 (int(agent['destination'][0] * self.cell_size + self.cell_size / 2),\n",
    "                                  int(agent['destination'][1] * self.cell_size + self.cell_size / 2)),\n",
    "                                 1)\n",
    "\n",
    "        pygame.display.flip()\n",
    "\n",
    "    def get_color(self, sugar_level):\n",
    "        \"\"\"\n",
    "        Get color based on sugar level.\n",
    "        \n",
    "        Args:\n",
    "            sugar_level (int): Sugar level at a grid cell.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: RGB color.\n",
    "        \"\"\"\n",
    "        if sugar_level == 0:\n",
    "            return (255, 255, 255)\n",
    "        else:\n",
    "            intensity = sugar_level / self.params['max_sugar']\n",
    "            return (255, 255, int(255 * (1 - intensity)))\n",
    "\n",
    "    def collect_data(self):\n",
    "        \"\"\"\n",
    "        Collect data for analysis.\n",
    "        \"\"\"\n",
    "        population = len(self.agents)\n",
    "        total_wealth = sum(agent['sugar'] for agent in self.agents)\n",
    "        average_wealth = total_wealth / population if population > 0 else 0\n",
    "\n",
    "        self.population_history.append(population)\n",
    "        self.average_wealth_history.append(average_wealth)\n",
    "        self.gini_coefficient_history.append(self.calculate_gini_coefficient())\n",
    "\n",
    "    def calculate_gini_coefficient(self):\n",
    "        \"\"\"\n",
    "        Calculate the Gini coefficient for wealth distribution.\n",
    "        \n",
    "        Returns:\n",
    "            float: Gini coefficient.\n",
    "        \"\"\"\n",
    "        if not self.agents:\n",
    "            return 0\n",
    "        wealth_values = sorted(agent['sugar'] for agent in self.agents)\n",
    "        cumulative_wealth = np.cumsum(wealth_values)\n",
    "        n = len(wealth_values)\n",
    "        return (np.sum((2 * np.arange(1, n + 1) - n - 1) * wealth_values) /\n",
    "                (n * np.sum(wealth_values)))\n",
    "\n",
    "    def plot_results(self):\n",
    "        \"\"\"\n",
    "        Plot the collected data.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        plt.subplot(131)\n",
    "        plt.plot(self.population_history)\n",
    "        plt.title('Population over Time')\n",
    "        plt.xlabel('Timestep')\n",
    "        plt.ylabel('Population')\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.plot(self.average_wealth_history)\n",
    "        plt.title('Average Wealth over Time')\n",
    "        plt.xlabel('Timestep')\n",
    "        plt.ylabel('Average Wealth')\n",
    "\n",
    "        plt.subplot(133)\n",
    "        plt.plot(self.gini_coefficient_history)\n",
    "        plt.title('Gini Coefficient over Time')\n",
    "        plt.xlabel('Timestep')\n",
    "        plt.ylabel('Gini Coefficient')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SugarscapeEnv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tune\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mppo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PPO\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSugarscapeEnv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SugarscapeEnv  \u001b[38;5;66;03m# Ensure SugarscapeEnv is defined in a previous cell\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Initialize Ray\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     ray\u001b[38;5;241m.\u001b[39minit(ignore_reinit_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'SugarscapeEnv'"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.algorithms.ppo import PPO\n",
    "from SugarscapeEnv import SugarscapeEnv  # Ensure SugarscapeEnv is defined in a previous cell\n",
    "\n",
    "def main():\n",
    "    # Initialize Ray\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "    \n",
    "    # Environment configuration\n",
    "    env_config = {\n",
    "        \"width\": 50,\n",
    "        \"height\": 50,\n",
    "        \"num_agents\": 100,  # Start with 100 agents for efficiency\n",
    "        \"cell_size\": 10,\n",
    "        \"show_sugar_levels\": False,\n",
    "        \"show_broadcast_radius\": False,  # Disable rendering during training\n",
    "        \"show_agent_paths\": False,\n",
    "        \"broadcast_radius\": 15,\n",
    "        \"seed\": 23,\n",
    "        \"render_mode\": False  # Disable rendering\n",
    "    }\n",
    "    \n",
    "    # Instantiate the environment to retrieve observation and action spaces\n",
    "    env_instance = SugarscapeEnv(config=env_config)\n",
    "    \n",
    "    # Define the configuration for PPO\n",
    "    config = {\n",
    "        \"env\": SugarscapeEnv,\n",
    "        \"env_config\": env_config,\n",
    "        \"num_gpus\": 0,  # Set to >0 if GPUs are available\n",
    "        \"num_workers\": 2,  # Adjust based on your CPU cores\n",
    "        \"framework\": \"torch\",  # or \"tf\" for TensorFlow\n",
    "        \"multiagent\": {\n",
    "            \"policies\": {\n",
    "                \"shared_policy\": (None, env_instance.observation_space, env_instance.action_space, {})\n",
    "            },\n",
    "            \"policy_mapping_fn\": lambda agent_id, episode, worker, **kwargs: \"shared_policy\",\n",
    "        },\n",
    "        \"model\": {\n",
    "            \"fcnet_hiddens\": [128, 128],\n",
    "            \"fcnet_activation\": \"relu\",\n",
    "        },\n",
    "        \"lr\": 5e-4,\n",
    "        \"num_sgd_iter\": 10,\n",
    "        \"sgd_minibatch_size\": 256,\n",
    "        \"train_batch_size\": 4000,\n",
    "        \"rollout_fragment_length\": 200,\n",
    "    }\n",
    "    \n",
    "    # Initialize the PPO algorithm\n",
    "    trainer = PPO(config=config, env=SugarscapeEnv)\n",
    "    \n",
    "    # Training loop parameters\n",
    "    num_iterations = 1000  # Adjust as needed\n",
    "    checkpoint_freq = 200  # Save checkpoint every 200 iterations\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        result = trainer.train()\n",
    "        \n",
    "        # Print progress every 100 iterations\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Iteration {i + 1}: average reward {result['episode_reward_mean']}\")\n",
    "        \n",
    "        # Save checkpoints periodically\n",
    "        if (i + 1) % checkpoint_freq == 0:\n",
    "            checkpoint = trainer.save()\n",
    "            print(f\"Checkpoint saved at {checkpoint}\")\n",
    "    \n",
    "    # Save the final model\n",
    "    final_checkpoint = trainer.save()\n",
    "    print(f\"Final checkpoint saved at {final_checkpoint}\")\n",
    "    \n",
    "    # Shutdown Ray\n",
    "    ray.shutdown()\n",
    "\n",
    "# Execute the training script\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[rllib] in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (2.37.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (8.1.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (3.13.1)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (4.19.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (4.25.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (1.4.1)\n",
      "Requirement already satisfied: requests in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (2.31.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (2.2.1)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (17.0.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (2024.2.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (0.1.8)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (0.28.1)\n",
      "Requirement already satisfied: lz4 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (4.3.3)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (0.24.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (1.13.0)\n",
      "Requirement already satisfied: typer in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (0.12.5)\n",
      "Requirement already satisfied: rich in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from ray[rllib]) (13.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from gymnasium==0.28.1->ray[rllib]) (1.26.3)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from gymnasium==0.28.1->ray[rllib]) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from gymnasium==0.28.1->ray[rllib]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from gymnasium==0.28.1->ray[rllib]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from gymnasium==0.28.1->ray[rllib]) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from click>=7.0->ray[rllib]) (0.4.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from jsonschema->ray[rllib]) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from jsonschema->ray[rllib]) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from jsonschema->ray[rllib]) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from jsonschema->ray[rllib]) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from pandas->ray[rllib]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from pandas->ray[rllib]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from pandas->ray[rllib]) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from requests->ray[rllib]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from requests->ray[rllib]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from requests->ray[rllib]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from requests->ray[rllib]) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from rich->ray[rllib]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from rich->ray[rllib]) (2.15.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from scikit-image->ray[rllib]) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from scikit-image->ray[rllib]) (10.2.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from scikit-image->ray[rllib]) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from scikit-image->ray[rllib]) (2024.8.10)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from scikit-image->ray[rllib]) (0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from typer->ray[rllib]) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->ray[rllib]) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\neo\\anaconda3\\envs\\acml\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ray[rllib]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ray[rllib]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray and RLlib are successfully installed and updated!\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.algorithms.ppo import PPO\n",
    "\n",
    "print(\"Ray and RLlib are successfully installed and updated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
